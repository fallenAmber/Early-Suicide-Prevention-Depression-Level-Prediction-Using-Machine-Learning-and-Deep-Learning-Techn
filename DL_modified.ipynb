{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of DL_modified.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"pZKbmI0Bdpf3"},"source":["\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S1yUzaSkbCSv"},"source":["%%time\n","import os\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import pandas as pd\n","import seaborn as sns\n","import re\n","import nltk\n","import json\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import regularizers\n","from keras import models\n","from keras import layers\n","from tensorflow.keras.layers import LSTM,GRU, Dropout\n","\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report \n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n","from sklearn.metrics import average_precision_score,roc_auc_score, roc_curve, precision_recall_curve\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n","from sklearn.pipeline import Pipeline\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XodLmiMcU2SD"},"source":["!pip install BnPreprocessing\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYNKi49FfgCL"},"source":["#read Data\n","data =pd.read_excel('/content/drive/MyDrive/Thesis/Shared/DFBA Train Data.xlsx')[0:6475]\n","data_df = data\n","text_data = data_df[\"text\"]\n","labels = data_df[\"label2\"]\n","classes = data_df[\"class2\"]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(labels)"],"metadata":{"id":"F0N06Hdc_BZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_four_label_droping(data_df):\n","  tag_list = []\n","  text_list = []\n","  for i in range(len(data_df)):\n","      if (data_df.class2[i] == 'anger' or data_df.class2[i] ==  'disapproval' or data_df.class2[i] == 'disgust'): \n","        tag = \"mild\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif (data_df.class2[i] == 'fear' or data_df.class2[i] ==  'nervousness' or data_df.class2[i] ==  'embarrassment' or data_df.class2[i] ==  'remorse'): \n","        tag = \"moderate\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif (data_df.class2[i] == 'sadness' or data_df.class2[i] == 'disappointment'): \n","        tag = \"severe\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif(data_df.class2[i] == 'joy' or data_df.class2[i] ==  'love' or data_df.class2[i] ==   'approval'or data_df.class2[i] ==  'amusement' ):\n","        tag = \"no\"      \n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","  \n","  new_df = pd.DataFrame(list(zip(text_list, tag_list)), columns = ['text', 'label'])   \n","\n","  return new_df\n","new_df = make_four_label_droping(data_df)"],"metadata":{"id":"B53xF-bInyt0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_two_class(data_df):\n","  tag_list = []\n","  for i in range(len(data_df)):\n","      if data_df.label2[i] == 'no': \n","        tag = \"non-depressed\"\n","        tag_list.append(tag)\n","      else: \n","        tag = \"depressed\"      \n","        tag_list.append(tag)   \n","  data_df['label'] = tag_list \n","  return data_df\n","new_df = make_two_class(data_df)"],"metadata":{"id":"zGDjAX54Sxgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_two_tag_droping(data_df):\n","  tag_list = []\n","  text_list = []\n","  for i in range(len(data_df)):\n","      if (data_df.class2[i] == 'anger' or data_df.class2[i] ==  'disapproval' or data_df.class2[i] == 'disgust'): \n","        tag = \"depressive\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif (data_df.class2[i] == 'fear' or data_df.class2[i] ==  'nervousness' or data_df.class2[i] ==  'embarrassment' or data_df.class2[i] ==  'remorse'): \n","        tag = \"depressive\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif (data_df.class2[i] == 'sadness' or data_df.class2[i] == 'disappointment'): \n","        tag = \"depressive\"\n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","      elif(data_df.class2[i] == 'joy' or data_df.class2[i] ==  'love' or data_df.class2[i] ==   'approval'or data_df.class2[i] ==  'amusement' ):\n","        tag = \"non-depressive\"      \n","        tag_list.append(tag)\n","        text_list.append(data_df.text[i])\n","  \n","  new_df = pd.DataFrame(list(zip(text_list, tag_list)), columns = ['text', 'label'])   \n","\n","  \n","\n","  return new_df\n","new_df = make_two_tag_droping(data_df)"],"metadata":{"id":"7mLHAt2BhNrt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_data = new_df[\"text\"]\n","labels = new_df[\"label\"]"],"metadata":{"id":"BVZAZWfPjAb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set(labels)"],"metadata":{"id":"y9px60ko_Yfi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install BnPreprocessing"],"metadata":{"id":"ROmkd1Ox3TNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import BnPreprocessing as pp\n","text_data = text_data.apply(pp.remove_noise)"],"metadata":{"id":"Of-Lks2W3QKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_df.to_excel(\"/content/drive/MyDrive/Thesis/Thesis Code/BenFEDAS_two_label.xlsx\", index = False)"],"metadata":{"id":"6sTToSTr_4VM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","#Encoding\n","from sklearn.preprocessing import LabelEncoder\n","label = LabelEncoder()\n","labels = label.fit_transform(labels)"],"metadata":{"id":"xSmOSQDHn-sX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Encoding\n","from sklearn.preprocessing import LabelEncoder\n","label = LabelEncoder()\n","labels = label.fit_transform(labels)"],"metadata":{"id":"Duj2hvFgepuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#One hot encoding\n","from sklearn.preprocessing import OneHotEncoder\n","\n","encoder = OneHotEncoder(sparse=False)\n","\n","class_labels = labels.values.reshape((labels.shape[0], 1))\n","labels = encoder.fit_transform(class_labels)\n"],"metadata":{"id":"e5xOP6KTs5Xq"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DrWvKMTTWoRM"},"source":["import BnPreprocessing as pp\n","text_data = text_data.apply(pp.remove_noise)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","train_data, test_data, train_labels, test_labels = train_test_split(text_data, labels, test_size=0.2, shuffle = True, random_state=42)\n","#train_data, sp_data, train_labels, sp_labels = train_test_split(text_data, labels, test_size=0.4, shuffle = False, random_state=42)\n","#val_data, test_data, val_labels, test_labels = train_test_split(sp_data, sp_labels, test_size=0.5, shuffle = False, random_state=42)\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","tokenizer = Tokenizer(oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(text_data)\n","vocab_size = len(tokenizer.word_index) + 1\n","max_length = 196\n","embedding_dim = 300\n","trunc_type='post'\n","padding_type='post'\n"," \n","training_sequences = tokenizer.texts_to_sequences(train_data)\n","training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","#val_sequences = tokenizer.texts_to_sequences(val_data)\n","#val_padded = pad_sequences(val_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","testing_sequences = tokenizer.texts_to_sequences(test_data)\n","testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","import numpy as np\n","training_padded = np.array(training_padded)\n","training_labels = np.array(train_labels)\n","#val_padded = np.array(val_padded)\n","#val_labels = np.array(val_labels)\n","testing_padded = np.array(testing_padded)\n","testing_labels = np.array(test_labels)"],"metadata":{"id":"9o-GFgLhvLQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = tf.keras.Sequential([\n","  tf.keras.layers.Embedding(input_dim=vocab_size, \n","                              output_dim=embedding_dim, \n","                              input_length=max_length),\n","    tf.keras.layers.Dense(512, activation=\"relu\"),\n","    tf.keras.layers.Dense(256, activation=\"relu\"),\n","    tf.keras.layers.Dense(4, activation ='softmax'),\n","  ])\n","  \n","\n","#model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n","#model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n","tensorboard_callback  = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","num_epochs = 50\n","history = model.fit(training_padded, training_labels,epochs=num_epochs, batch_size =32, validation_data=(testing_padded, testing_labels), validation_batch_size =16, callbacks=[tensorboard_callback], verbose=2)"],"metadata":{"id":"ZOC5Iwet4Ogy"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qP0Eqr-SWJIP"},"source":["lr =tf.keras.optimizers.Adam(\n","    learning_rate= 1e-04,\n","    beta_1=0.9,\n","    beta_2=0.999,\n","    epsilon=1e-08,\n","    amsgrad=False,\n","    name=\"Adam\"\n",")\n","model =  tf.keras.Sequential([\n","                              tf.keras.layers.Embedding(input_dim=vocab_size, \n","                              output_dim=embedding_dim, \n","                              input_length=max_length),\n","                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n","                              tf.keras.layers.Dropout(0.8),\n","                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","                              tf.keras.layers.Dropout(0.8),\n","                              tf.keras.layers.Dense(32,kernel_regularizer=regularizers.l2(0.01),activation=\"relu\"),\n","                              tf.keras.layers.Dropout(0.2),\n","                              tf.keras.layers.Dense(2, activation='softmax')\n","])\n","model.compile(loss='sparse_categorical_crossentropy',optimizer=lr,metrics=['accuracy'])\n","#model.compile(loss='binary_crossentropy',optimizer=lr,metrics=['accuracy'])\n","#model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n","tensorboard_callback  = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","num_epochs = 50\n","history = model.fit(training_padded, training_labels,epochs=num_epochs, batch_size =32, validation_data=(testing_padded, testing_labels), validation_batch_size =16, callbacks=[tensorboard_callback], verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"ZG7FJhKoSWDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## অ্যাক্যুরেসি  ম্যাটপ্লটলিব দিয়ে\n","\n","import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  \n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.savefig(\"/content/drive/MyDrive/Thesis/Thesis Code/thesis result/196l_200_64_32_unit_Accuracy .2_test_.8.8.2dropout_4bilstm drop.eps\",format = 'eps',dpi = 1000)\n","  \n","plot_graphs(history, \"accuracy\")\n"],"metadata":{"id":"Y9PVhD0GLg66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##  লস, ম্যাটপ্লটলিব দিয়ে\n","\n","import matplotlib.pyplot as plt\n","\n","def plot_graphs(history, string):\n","  \n","  plt.plot(history.history[string])\n","  plt.plot(history.history['val_'+string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.legend([string, 'val_'+string])\n","  plt.savefig(\"/content/drive/MyDrive/Thesis/Thesis Code/thesis result/196l_200_64_32_unit_loss .2_test_.8.8.2dropout_4bilstm drop.eps\",format = 'eps',dpi = 1000)\n","  \n","plot_graphs(history, \"loss\")"],"metadata":{"id":"-zHQ-S-KS5bx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","ypred = model.predict(testing_padded, verbose=2)\n","ypred = np.argmax(ypred, axis=1)\n","print(classification_report(test_labels, ypred))\n","confusion_matrix(test_labels, ypred)\n"],"metadata":{"id":"EBVpprvLJ0ix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.evaluate(test_data, test_labels, verbose=0)\n"],"metadata":{"id":"DUlLttLOUZc9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_labels.shape"],"metadata":{"id":"xXIsgoQHiOkt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ypred.shape"],"metadata":{"id":"tBRZyuDkiVkK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas\n","report = classification_report(test_labels, ypred, output_dict=True)\n","df = pandas.DataFrame(report).transpose().round(decimals=2)\n","df.to_csv('/content/drive/MyDrive/Thesis/Result/effect_length_embedding/200l_300e__20_epoch_report_4_test_bilstm_drop.csv')\n","report1 = confusion_matrix(test_labels, ypred)\n","df = pandas.DataFrame(report1)\n","df.to_csv('/content/drive/MyDrive/Thesis/Result/effect_length_embedding/200l_300e_20_epoch_confusion_4_test_bilstm drop.csv')"],"metadata":{"id":"t8Y0c5WnNM7j"},"execution_count":null,"outputs":[]}]}